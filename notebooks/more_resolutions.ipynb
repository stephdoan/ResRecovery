{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')\n",
    "from features import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbit_rate = 1/125000\n",
    "\n",
    "low_fp = '../data/240p/' \n",
    "threesixty_fp = '../data/360p/' \n",
    "med_fp = '../data/480p/'\n",
    "seventwenty_fp = '../data/720p/' \n",
    "high_fp = '../data/1080p/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dfs = []\n",
    "for file in os.listdir(low_fp):\n",
    "    if file != '.ipynb_checkpoints' and file != '.DS_Store':\n",
    "        low_dfs.append(pd.read_csv(low_fp+file))\n",
    "    \n",
    "threesixty_dfs = []\n",
    "for file in os.listdir(threesixty_fp):\n",
    "    if file != '.ipynb_checkpoints' and file != '.DS_Store':\n",
    "        threesixty_dfs.append(pd.read_csv(threesixty_fp+file))\n",
    "        \n",
    "med_dfs = []\n",
    "for file in os.listdir(med_fp):\n",
    "    if file != '.ipynb_checkpoints' and file != '.DS_Store':\n",
    "        med_dfs.append(pd.read_csv(med_fp+file))\n",
    "        \n",
    "seventwenty_dfs = []\n",
    "for file in os.listdir(seventwenty_fp):\n",
    "    if file != '.ipynb_checkpoints' and file != '.DS_Store':\n",
    "        seventwenty_dfs.append(pd.read_csv(seventwenty_fp+file))\n",
    "    \n",
    "high_dfs = []\n",
    "for file in os.listdir(high_fp):\n",
    "    if file != '.ipynb_checkpoints' and file != '.DS_Store':\n",
    "        high_dfs.append(pd.read_csv(high_fp+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdoan_low = pd.read_csv(low_fp + 'stdoan-101-action-240p-20201127.csv')\n",
    "# stdoan_med = pd.read_csv(med_fp + 'stdoan-101-action-480p-20201127.csv')\n",
    "# stdoan_high = pd.read_csv(high_fp + 'stdoan-101-action-1080p-20201127.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ms = []\n",
    "for df in low_dfs:\n",
    "    low_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "threesixty_ms = []\n",
    "for df in threesixty_dfs:\n",
    "    threesixty_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "med_ms = []\n",
    "for df in med_dfs:\n",
    "    med_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "seventwenty_ms = []\n",
    "for df in seventwenty_dfs:\n",
    "    seventwenty_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "high_ms = []\n",
    "for df in high_dfs:\n",
    "    high_ms.append(convert_ms_df(df,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_ms = convert_ms_df(stdoan_low, True)\n",
    "# med_ms = convert_ms_df(stdoan_med, True)\n",
    "# high_ms = convert_ms_df(stdoan_high, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_resamples = []\n",
    "for df in low_ms:\n",
    "    low_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "threesixty_resamples = []\n",
    "for df in threesixty_ms:\n",
    "    threesixty_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "med_resamples = []\n",
    "for df in med_ms:\n",
    "    med_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "seventwenty_resamples = []\n",
    "for df in seventwenty_ms:\n",
    "    seventwenty_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "high_resamples = []\n",
    "for df in high_ms:\n",
    "    high_resamples.append(df.resample('500ms', on='Time').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_resample = low_ms.resample('500ms', on='Time').sum()\n",
    "# med_resample = med_ms.resample('500ms', on='Time').sum()\n",
    "# high_resample = high_ms.resample('500ms', on='Time').sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take the aggregate features of the whole chunk; download and upload\n",
    "def agg_feat(df, col):\n",
    "    return [np.mean(df[col]), np.std(df[col])]\n",
    "\n",
    "## take the ratio of upload:download packets\n",
    "def pkt_ratio(df):\n",
    "    ms_df = convert_ms_df(df, True)\n",
    "    local = np.sum(ms_df['pkt_src'] == '1') \n",
    "    server = np.sum(ms_df['pkt_src'] == '2') \n",
    "    return local / server\n",
    "\n",
    "## take the ratio of upload:download bytes\n",
    "def bytes_ratio(df):\n",
    "    local = df['1->2Bytes'].sum()\n",
    "    server = df['2->1Bytes'].sum()\n",
    "    return local / server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Related Aggregate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finds the peaks with mean + 2(1) std\n",
    "## run the above aggregate functions on the peaks only??\n",
    "\n",
    "def get_peak_loc(df, col, invert=False):\n",
    "  'invert arg allows you to get values not considered peaks'\n",
    "  df_avg = df[col].mean()\n",
    "  df_std = df[col].std()\n",
    "  \n",
    "  threshold = df_avg + (1 * df_std)\n",
    "  \n",
    "  if invert:\n",
    "    return np.array(df[col] < threshold)\n",
    "  \n",
    "  else:\n",
    "    return np.array(df[col] > threshold)\n",
    "\n",
    "## np.mean, np.var, np.std - think of more?  \n",
    "def peak_time_diff(df, col):\n",
    "  '''\n",
    "  mess around with the different inputs for function. \n",
    "  variance seems to inflate the difference betweent the two the most with litte\n",
    "  to no data manipulation. however, currently trying things like\n",
    "  squaring the data before taking the aggregate function to exaggerate\n",
    "  differences (moderate success??)\n",
    "  '''\n",
    "  peaks = df[get_peak_loc(df, col)]\n",
    "  peaks['Time'] = peaks['Time'] - peaks['Time'].min()\n",
    "  time_diff = np.diff(peaks['Time'] ** 2)\n",
    "  return [np.mean(time_diff), np.std(time_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def peak_times(df,col,thresh):\n",
    "    x = df[col]\n",
    "    peaks, _ = find_peaks(x, height=thresh)\n",
    "    if list(peaks) == []:\n",
    "        return [-1]\n",
    "    times = df.iloc[peaks]['Time'].values\n",
    "    time_between_peaks = [times[i]-times[i-1]for i in range(1,len(times))]\n",
    "    #print(time_between_peaks)\n",
    "    #time_between_peaks[0]=0\n",
    "    if time_between_peaks == []:\n",
    "        return -1\n",
    "    return time_between_peaks\n",
    "\n",
    "def num_peaks(df,col,thresh):\n",
    "    x = df[col]\n",
    "    peaks, _ = find_peaks(x, height=thresh)\n",
    "    return len(peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_features(df, col):\n",
    "\n",
    "    \"\"\"\n",
    "    welch implemention of spectral features\n",
    "    resample the data before inputting (might change prereq depending on\n",
    "    resource allocation)\n",
    "    \"\"\"\n",
    "\n",
    "    f, Pxx_den = sp.signal.welch(df[col], fs=2)\n",
    "    Pxx_den = np.sqrt(Pxx_den)\n",
    "\n",
    "    peaks = sp.signal.find_peaks(Pxx_den)[0]\n",
    "    prominences = sp.signal.peak_prominences(Pxx_den, peaks)[0]\n",
    "\n",
    "    idx_max = prominences.argmax()\n",
    "    loc_max = peaks[idx_max]\n",
    "\n",
    "    return [f[loc_max], Pxx_den[loc_max], prominences[idx_max]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking & Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wip; need to decide chunk size eventually\n",
    "## should we also make this chunking feature be our feature creation?\n",
    "\n",
    "def chunk_data(df, interval=60):\n",
    "\n",
    "    \"\"\"\n",
    "    takes in a filepath to the data you want to chunk and feature engineer\n",
    "    chunks our data into a specified time interval\n",
    "    each chunk is then turned into an observation to be fed into our classifier\n",
    "    \"\"\"\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    df['Time'] = df['Time'] - df['Time'].min()\n",
    "    \n",
    "    total_chunks = np.floor(df['Time'].max() / interval).astype(int)\n",
    "\n",
    "    for chunk in np.arange(total_chunks):\n",
    "      \n",
    "        start = chunk * interval\n",
    "        end = (chunk+1) * interval\n",
    "\n",
    "        temp_df = (df[(df['Time'] >= start) & (df['Time'] < end)])\n",
    "        \n",
    "        df_list.append(temp_df)\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(dfs, interval=60):\n",
    "\n",
    "  features = [\n",
    "    'dwl_peak_freq',\n",
    "    'dwl_peak_prom',\n",
    "    'dwl_max_psd',\n",
    "    'dwl_bytes_avg',\n",
    "    'dwl_bytes_std',\n",
    "    'dwl_peak_avg',\n",
    "    'dwl_peak_std',\n",
    "    'upl_peak_freq',\n",
    "    'upl_peak_prom',\n",
    "    'upl_max_psd',\n",
    "    'upl_bytes_avg',\n",
    "    'upl_bytes_std',\n",
    "    'upl_peak_avg',\n",
    "    'upl_peak_std',\n",
    "    'dwl_time_peak',#'IMAN_up_time_peak',\n",
    "      'dwl_num_peak'#,'IMAN_up_num_peak'\n",
    "  ]  \n",
    "\n",
    "  vals = []\n",
    "  for df in dfs:\n",
    "      df_chunks = chunk_data(df, interval)\n",
    "\n",
    "      for chunk in df_chunks:\n",
    "\n",
    "        preproc = convert_ms_df(chunk, True)\n",
    "        upl_bytes = preproc[preproc['pkt_src'] == '1'].resample('500ms', on='Time').sum()\n",
    "        dwl_bytes = preproc[preproc['pkt_src'] == '2'].resample('500ms', on='Time').sum()\n",
    "\n",
    "        ## spectral features\n",
    "        dwl_spectral = spectral_features(dwl_bytes, 'pkt_size')\n",
    "        upl_spectral = spectral_features(upl_bytes, 'pkt_size')\n",
    "\n",
    "        ## aggregate features\n",
    "        dwl_agg = agg_feat(chunk, '2->1Bytes')\n",
    "        upl_agg = agg_feat(chunk, '1->2Bytes')\n",
    "\n",
    "        ## peak features\n",
    "        dwl_peak = peak_time_diff(chunk, '2->1Bytes')\n",
    "        upl_peak = peak_time_diff(chunk, '1->2Bytes')\n",
    "        \n",
    "        ## iman's time between peak \n",
    "        iman_dwn_time_peak = np.mean(peak_times(chunk,'2->1Bytes',1000000))\n",
    "        #iman_up_time_peak = np.mean(peak_times(chunk,'1->2Bytes',50000))\n",
    "        \n",
    "        ## iman's num peak\n",
    "        iman_dwn_num_peak = num_peaks(chunk,'2->1Bytes',1000000)\n",
    "        #iman_up_num_peak = num_peaks(chunk,'1->2Bytes',50000)\n",
    "\n",
    "\n",
    "        \n",
    "        feat_val = np.hstack((\n",
    "          dwl_spectral,\n",
    "          dwl_agg,\n",
    "          dwl_peak,\n",
    "          upl_spectral,\n",
    "          upl_agg,\n",
    "          upl_peak,\n",
    "            iman_dwn_time_peak,#iman_up_time_peak,\n",
    "            iman_dwn_num_peak,#iman_up_num_peak\n",
    "        ))\n",
    "\n",
    "        vals.append(feat_val)\n",
    "    \n",
    "  return pd.DataFrame(columns=features, data=vals).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 s, sys: 220 ms, total: 21.5 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "low_feat = create_features(low_dfs, 120)\n",
    "threesixty_feat = create_features(threesixty_dfs, 120)\n",
    "med_feat = create_features(med_dfs, 120)\n",
    "seventwenty_feat = create_features(seventwenty_dfs, 120)\n",
    "high_feat = create_features(high_dfs, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_feat['resolution'] = '240p'\n",
    "threesixty_feat['resolution'] = '360p'\n",
    "med_feat['resolution'] = '480p'\n",
    "seventwenty_feat['resolution'] = '720p'\n",
    "high_feat['resolution'] = '1080p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([low_feat, threesixty_feat, med_feat,seventwenty_feat, high_feat]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SELECT SUBSETS OF FEATURES\n",
    "\n",
    "#training = training[['dwl_bytes_avg','dwl_peak_prom','upl_bytes_std','dwl_bytes_std','upl_peak_std','resolution']]\n",
    "#training = training[['dwl_bytes_avg','upl_max_psd','dwl_max_psd','upl_peak_prom','dwl_num_peak','dwl_peak_prom','resolution']]\n",
    "#training = training[['dwl_max_psd','upl_max_psd','dwl_peak_prom','upl_peak_prom','dwl_num_peak','dwl_bytes_avg','upl_bytes_std','upl_bytes_avg','resolution']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwl_peak_freq</th>\n",
       "      <th>dwl_peak_prom</th>\n",
       "      <th>dwl_max_psd</th>\n",
       "      <th>dwl_bytes_avg</th>\n",
       "      <th>dwl_bytes_std</th>\n",
       "      <th>dwl_peak_avg</th>\n",
       "      <th>dwl_peak_std</th>\n",
       "      <th>upl_peak_freq</th>\n",
       "      <th>upl_peak_prom</th>\n",
       "      <th>upl_max_psd</th>\n",
       "      <th>upl_bytes_avg</th>\n",
       "      <th>upl_bytes_std</th>\n",
       "      <th>upl_peak_avg</th>\n",
       "      <th>upl_peak_std</th>\n",
       "      <th>dwl_time_peak</th>\n",
       "      <th>dwl_num_peak</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>3.172323e+05</td>\n",
       "      <td>3.010390e+05</td>\n",
       "      <td>105818.018349</td>\n",
       "      <td>292073.412690</td>\n",
       "      <td>947.769231</td>\n",
       "      <td>980.253668</td>\n",
       "      <td>0.133891</td>\n",
       "      <td>14302.110672</td>\n",
       "      <td>12720.120720</td>\n",
       "      <td>6901.944954</td>\n",
       "      <td>16862.760631</td>\n",
       "      <td>947.769231</td>\n",
       "      <td>980.253668</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.200837</td>\n",
       "      <td>2.116595e+05</td>\n",
       "      <td>2.023631e+05</td>\n",
       "      <td>56392.975904</td>\n",
       "      <td>181129.552286</td>\n",
       "      <td>2242.666667</td>\n",
       "      <td>1420.062049</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>12269.692224</td>\n",
       "      <td>11698.225453</td>\n",
       "      <td>3695.939759</td>\n",
       "      <td>9105.882828</td>\n",
       "      <td>2242.666667</td>\n",
       "      <td>1420.062049</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>2.252769e+05</td>\n",
       "      <td>2.128232e+05</td>\n",
       "      <td>51312.250000</td>\n",
       "      <td>203432.423015</td>\n",
       "      <td>2080.800000</td>\n",
       "      <td>2320.069602</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>13340.341481</td>\n",
       "      <td>12745.342358</td>\n",
       "      <td>3723.068182</td>\n",
       "      <td>10219.868095</td>\n",
       "      <td>2080.800000</td>\n",
       "      <td>2320.069602</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193277</td>\n",
       "      <td>1.933348e+05</td>\n",
       "      <td>1.817832e+05</td>\n",
       "      <td>39377.755319</td>\n",
       "      <td>151199.194042</td>\n",
       "      <td>1656.200000</td>\n",
       "      <td>1367.217378</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>11055.763175</td>\n",
       "      <td>10565.957392</td>\n",
       "      <td>3055.329787</td>\n",
       "      <td>7590.302042</td>\n",
       "      <td>1656.200000</td>\n",
       "      <td>1367.217378</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125523</td>\n",
       "      <td>1.908308e+05</td>\n",
       "      <td>1.840692e+05</td>\n",
       "      <td>63535.761905</td>\n",
       "      <td>191208.720401</td>\n",
       "      <td>1513.800000</td>\n",
       "      <td>1348.799970</td>\n",
       "      <td>0.100418</td>\n",
       "      <td>12298.882370</td>\n",
       "      <td>11778.581777</td>\n",
       "      <td>4370.000000</td>\n",
       "      <td>9625.049335</td>\n",
       "      <td>1513.800000</td>\n",
       "      <td>1348.799970</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>1.295016e+06</td>\n",
       "      <td>1.287103e+06</td>\n",
       "      <td>233169.513514</td>\n",
       "      <td>569860.008211</td>\n",
       "      <td>936.333333</td>\n",
       "      <td>666.245992</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>61418.518635</td>\n",
       "      <td>60301.660623</td>\n",
       "      <td>12333.486486</td>\n",
       "      <td>27193.069522</td>\n",
       "      <td>936.333333</td>\n",
       "      <td>666.245992</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.096070</td>\n",
       "      <td>1.164929e+06</td>\n",
       "      <td>1.092980e+06</td>\n",
       "      <td>228929.241379</td>\n",
       "      <td>516817.245537</td>\n",
       "      <td>1002.272727</td>\n",
       "      <td>1507.679378</td>\n",
       "      <td>0.096070</td>\n",
       "      <td>55312.103148</td>\n",
       "      <td>52585.487555</td>\n",
       "      <td>11895.758621</td>\n",
       "      <td>24587.033458</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>1546.366790</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>7.298143e+05</td>\n",
       "      <td>6.369195e+05</td>\n",
       "      <td>203555.510204</td>\n",
       "      <td>546653.912209</td>\n",
       "      <td>921.600000</td>\n",
       "      <td>904.036526</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>35513.168457</td>\n",
       "      <td>32592.826118</td>\n",
       "      <td>10648.867347</td>\n",
       "      <td>26150.031304</td>\n",
       "      <td>921.600000</td>\n",
       "      <td>904.036526</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>9.803294e+05</td>\n",
       "      <td>9.645212e+05</td>\n",
       "      <td>248339.244444</td>\n",
       "      <td>588179.115896</td>\n",
       "      <td>784.083333</td>\n",
       "      <td>749.898155</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>46757.514827</td>\n",
       "      <td>46135.557627</td>\n",
       "      <td>12752.111111</td>\n",
       "      <td>27889.468266</td>\n",
       "      <td>784.083333</td>\n",
       "      <td>749.898155</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>3.468969e+05</td>\n",
       "      <td>2.680521e+05</td>\n",
       "      <td>110726.989130</td>\n",
       "      <td>392011.975337</td>\n",
       "      <td>308.166667</td>\n",
       "      <td>306.419330</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>19049.654936</td>\n",
       "      <td>16006.844090</td>\n",
       "      <td>6296.315217</td>\n",
       "      <td>18761.476452</td>\n",
       "      <td>308.166667</td>\n",
       "      <td>306.419330</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dwl_peak_freq  dwl_peak_prom   dwl_max_psd  dwl_bytes_avg  dwl_bytes_std  \\\n",
       "0         0.201681   3.172323e+05  3.010390e+05  105818.018349  292073.412690   \n",
       "1         0.200837   2.116595e+05  2.023631e+05   56392.975904  181129.552286   \n",
       "2         0.101266   2.252769e+05  2.128232e+05   51312.250000  203432.423015   \n",
       "3         0.193277   1.933348e+05  1.817832e+05   39377.755319  151199.194042   \n",
       "4         0.125523   1.908308e+05  1.840692e+05   63535.761905  191208.720401   \n",
       "..             ...            ...           ...            ...            ...   \n",
       "182       0.093617   1.295016e+06  1.287103e+06  233169.513514  569860.008211   \n",
       "183       0.096070   1.164929e+06  1.092980e+06  228929.241379  516817.245537   \n",
       "184       0.184874   7.298143e+05  6.369195e+05  203555.510204  546653.912209   \n",
       "185       0.184211   9.803294e+05  9.645212e+05  248339.244444  588179.115896   \n",
       "186       0.092437   3.468969e+05  2.680521e+05  110726.989130  392011.975337   \n",
       "\n",
       "     dwl_peak_avg  dwl_peak_std  upl_peak_freq  upl_peak_prom   upl_max_psd  \\\n",
       "0      947.769231    980.253668       0.133891   14302.110672  12720.120720   \n",
       "1     2242.666667   1420.062049       0.203390   12269.692224  11698.225453   \n",
       "2     2080.800000   2320.069602       0.100840   13340.341481  12745.342358   \n",
       "3     1656.200000   1367.217378       0.100840   11055.763175  10565.957392   \n",
       "4     1513.800000   1348.799970       0.100418   12298.882370  11778.581777   \n",
       "..            ...           ...            ...            ...           ...   \n",
       "182    936.333333    666.245992       0.093617   61418.518635  60301.660623   \n",
       "183   1002.272727   1507.679378       0.096070   55312.103148  52585.487555   \n",
       "184    921.600000    904.036526       0.184874   35513.168457  32592.826118   \n",
       "185    784.083333    749.898155       0.184211   46757.514827  46135.557627   \n",
       "186    308.166667    306.419330       0.092437   19049.654936  16006.844090   \n",
       "\n",
       "     upl_bytes_avg  upl_bytes_std  upl_peak_avg  upl_peak_std  dwl_time_peak  \\\n",
       "0      6901.944954   16862.760631    947.769231    980.253668      13.000000   \n",
       "1      3695.939759    9105.882828   2242.666667   1420.062049      -1.000000   \n",
       "2      3723.068182   10219.868095   2080.800000   2320.069602      -1.000000   \n",
       "3      3055.329787    7590.302042   1656.200000   1367.217378      -1.000000   \n",
       "4      4370.000000    9625.049335   1513.800000   1348.799970      -1.000000   \n",
       "..             ...            ...           ...           ...            ...   \n",
       "182   12333.486486   27193.069522    936.333333    666.245992      10.600000   \n",
       "183   11895.758621   24587.033458   1102.500000   1546.366790      10.571429   \n",
       "184   10648.867347   26150.031304    921.600000    904.036526      13.333333   \n",
       "185   12752.111111   27889.468266    784.083333    749.898155       9.700000   \n",
       "186    6296.315217   18761.476452    308.166667    306.419330      11.000000   \n",
       "\n",
       "     dwl_num_peak resolution  \n",
       "0             2.0       240p  \n",
       "1             0.0       240p  \n",
       "2             1.0       240p  \n",
       "3             0.0       240p  \n",
       "4             0.0       240p  \n",
       "..            ...        ...  \n",
       "182          11.0      1080p  \n",
       "183           8.0      1080p  \n",
       "184           7.0      1080p  \n",
       "185          11.0      1080p  \n",
       "186           4.0      1080p  \n",
       "\n",
       "[187 rows x 17 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training.drop(columns=['resolution']), training['resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "#classifier = RandomForestClassifier(n_estimators = 100, criterion = 'gini', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['480p', '720p', '720p', '360p', '720p', '360p', '360p', '360p',\n",
       "       '720p', '480p'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN ON TEST DATA\n",
    "classifier.fit(X,y)\n",
    "low_test = pd.read_csv('../data/test/sgs008-109-action-480p-20210202.csv')\n",
    "#low_test = pd.read_csv('../data/test/sgs008-109-action-720p-20210213.csv')\n",
    "low_test = pd.read_csv('../data/test/stdoan-102-action-720p-20201206.csv')\n",
    "\n",
    "\n",
    "low_feat = create_features([low_test], 120)\n",
    "\n",
    "test_low = low_feat#[['dwl_max_psd','upl_max_psd','dwl_peak_prom','upl_peak_prom','dwl_num_peak','dwl_bytes_avg','upl_bytes_std','upl_bytes_avg']]\n",
    "y_pred = classifier.predict(test_low)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR VALIDATION SET\n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Group</th>\n",
       "      <th>1080p</th>\n",
       "      <th>240p</th>\n",
       "      <th>360p</th>\n",
       "      <th>480p</th>\n",
       "      <th>720p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1080p</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240p</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360p</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480p</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720p</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Group  1080p  240p  360p  480p  720p\n",
       "Actual Group                                  \n",
       "1080p               13     0     0     0     0\n",
       "240p                 0     9     0     0     0\n",
       "360p                 0     1     5     0     0\n",
       "480p                 0     0     1    11     0\n",
       "720p                 2     0     0     0     5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.crosstab(y_test, y_pred, rownames=['Actual Group'], colnames=['Predicted Group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92857143, 0.94736842, 0.83333333, 0.95652174, 0.83333333])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9148936170212766"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6       , 0.85      , 0.9       , 0.85      , 0.7       ,\n",
       "       0.95      , 0.9       , 1.        , 0.93333333, 0.6       ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(classifier,X,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['dwl_bytes_avg','dwl_peak_prom','upl_bytes_std','dwl_bytes_std','upl_peak_std']\n",
    "# importances = classifier.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# for i in indices:\n",
    "#     print(features[i],': ',importances[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['dwl_bytes_avg','upl_max_psd','dwl_max_psd','upl_peak_prom','dwl_num_peak','dwl_peak_prom']\n",
    "# importances = classifier.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# for i in indices:\n",
    "#     print(features[i],': ',importances[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwl_peak_prom :  0.12932674112109813\n",
      "dwl_max_psd :  0.12317735884094977\n",
      "dwl_bytes_avg :  0.11604856195717536\n",
      "dwl_time_peak :  0.09693324838411006\n",
      "upl_max_psd :  0.09256348375010617\n",
      "dwl_num_peak :  0.08788893328210072\n",
      "dwl_bytes_std :  0.07971873844951466\n",
      "upl_peak_prom :  0.06778216380896335\n",
      "upl_bytes_avg :  0.055120304930472326\n",
      "upl_bytes_std :  0.05025839868824128\n",
      "dwl_peak_avg :  0.026375183218262915\n",
      "dwl_peak_std :  0.020286999863416814\n",
      "upl_peak_avg :  0.015660424192193427\n",
      "upl_peak_std :  0.014268447510740866\n",
      "upl_peak_freq :  0.01338761263014186\n",
      "dwl_peak_freq :  0.011203399372512236\n"
     ]
    }
   ],
   "source": [
    "features = ['dwl_peak_freq','dwl_peak_prom','dwl_max_psd','dwl_bytes_avg','dwl_bytes_std','dwl_peak_avg',\n",
    "            'dwl_peak_std','upl_peak_freq','upl_peak_prom','upl_max_psd','upl_bytes_avg','upl_bytes_std',\n",
    "            'upl_peak_avg','upl_peak_std','dwl_time_peak','dwl_num_peak']\n",
    "importances = classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in indices:\n",
    "    print(features[i],': ',importances[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing that feature method functions correctly\n",
    "\n",
    "# l_start = 0 \n",
    "# l_end = 60\n",
    "\n",
    "# test_chunk = stdoan_low.copy()\n",
    "# test_chunk['Time'] = test_chunk['Time'] - test_chunk['Time'].min()\n",
    "# low_chunk = stdoan_low[(stdoan_low['Time'] >= 0) & (stdoan_low['Time'] < 60)]\n",
    "\n",
    "# low_chunk_ms = convert_ms_df(low_chunk, True)\n",
    "\n",
    "# upl_ms = low_chunk_ms[low_chunk_ms['pkt_src'] == '1']\n",
    "# dwl_ms = low_chunk_ms[low_chunk_ms['pkt_src'] == '2']\n",
    "\n",
    "# dwl_chunk_rs = dwl_ms.resample('500ms', on='Time').sum()\n",
    "\n",
    "# f_dwl, Pxx_dwl = sp.signal.welch(dwl_chunk_rs['pkt_size'], fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
