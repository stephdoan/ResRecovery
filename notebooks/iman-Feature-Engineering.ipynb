{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')\n",
    "from features import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbit_rate = 1/125000\n",
    "\n",
    "low_fp = '../data/240p/' \n",
    "med_fp = '../data/480p/'\n",
    "high_fp = '../data/1080p/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dfs = []\n",
    "for file in os.listdir(low_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        low_dfs.append(pd.read_csv(low_fp+file))\n",
    "    \n",
    "med_dfs = []\n",
    "for file in os.listdir(med_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        med_dfs.append(pd.read_csv(med_fp+file))\n",
    "    \n",
    "high_dfs = []\n",
    "for file in os.listdir(high_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        high_dfs.append(pd.read_csv(high_fp+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdoan_low = pd.read_csv(low_fp + 'stdoan-101-action-240p-20201127.csv')\n",
    "# stdoan_med = pd.read_csv(med_fp + 'stdoan-101-action-480p-20201127.csv')\n",
    "# stdoan_high = pd.read_csv(high_fp + 'stdoan-101-action-1080p-20201127.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ms = []\n",
    "for df in low_dfs:\n",
    "    low_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "med_ms = []\n",
    "for df in med_dfs:\n",
    "    med_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "high_ms = []\n",
    "for df in high_dfs:\n",
    "    high_ms.append(convert_ms_df(df,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_ms = convert_ms_df(stdoan_low, True)\n",
    "# med_ms = convert_ms_df(stdoan_med, True)\n",
    "# high_ms = convert_ms_df(stdoan_high, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_resamples = []\n",
    "for df in low_ms:\n",
    "    low_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "med_resamples = []\n",
    "for df in med_ms:\n",
    "    med_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "high_resamples = []\n",
    "for df in high_ms:\n",
    "    high_resamples.append(df.resample('500ms', on='Time').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_resample = low_ms.resample('500ms', on='Time').sum()\n",
    "# med_resample = med_ms.resample('500ms', on='Time').sum()\n",
    "# high_resample = high_ms.resample('500ms', on='Time').sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take the aggregate features of the whole chunk; download and upload\n",
    "def agg_feat(df, col):\n",
    "    return [np.mean(df[col]), np.std(df[col])]\n",
    "\n",
    "## take the ratio of upload:download packets\n",
    "def pkt_ratio(df):\n",
    "    ms_df = convert_ms_df(df, True)\n",
    "    local = np.sum(ms_df['pkt_src'] == '1') \n",
    "    server = np.sum(ms_df['pkt_src'] == '2') \n",
    "    return local / server\n",
    "\n",
    "## take the ratio of upload:download bytes\n",
    "def bytes_ratio(df):\n",
    "    local = df['1->2Bytes'].sum()\n",
    "    server = df['2->1Bytes'].sum()\n",
    "    return local / server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Related Aggregate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finds the peaks with mean + 2(1) std\n",
    "## run the above aggregate functions on the peaks only??\n",
    "\n",
    "def get_peak_loc(df, col, invert=False):\n",
    "  'invert arg allows you to get values not considered peaks'\n",
    "  df_avg = df[col].mean()\n",
    "  df_std = df[col].std()\n",
    "  \n",
    "  threshold = df_avg + (1 * df_std)\n",
    "  \n",
    "  if invert:\n",
    "    return np.array(df[col] < threshold)\n",
    "  \n",
    "  else:\n",
    "    return np.array(df[col] > threshold)\n",
    "\n",
    "## np.mean, np.var, np.std - think of more?  \n",
    "def peak_time_diff(df, col):\n",
    "  '''\n",
    "  mess around with the different inputs for function. \n",
    "  variance seems to inflate the difference betweent the two the most with litte\n",
    "  to no data manipulation. however, currently trying things like\n",
    "  squaring the data before taking the aggregate function to exaggerate\n",
    "  differences (moderate success??)\n",
    "  '''\n",
    "  peaks = df[get_peak_loc(df, col)]\n",
    "  peaks['Time'] = peaks['Time'] - peaks['Time'].min()\n",
    "  time_diff = np.diff(peaks['Time'] ** 2)\n",
    "  return [np.mean(time_diff), np.var(time_diff), np.std(time_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def peak_times(df,col,thresh):\n",
    "    x = df[col]\n",
    "    peaks, _ = find_peaks(x, height=thresh)\n",
    "    if list(peaks) == []:\n",
    "        return [-1]\n",
    "    times = df.iloc[peaks]['Time'].values\n",
    "    time_between_peaks = [times[i]-times[i-1]for i in range(1,len(times))]\n",
    "    #print(time_between_peaks)\n",
    "    #time_between_peaks[0]=0\n",
    "    if time_between_peaks == []:\n",
    "        return -1\n",
    "    return time_between_peaks\n",
    "\n",
    "def num_peaks(df,col,thresh):\n",
    "    x = df[col]\n",
    "    peaks, _ = find_peaks(x, height=thresh)\n",
    "    return len(peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_features(df, col):\n",
    "\n",
    "    \"\"\"\n",
    "    welch implemention of spectral features\n",
    "    resample the data before inputting (might change prereq depending on\n",
    "    resource allocation)\n",
    "    \"\"\"\n",
    "\n",
    "    f, Pxx_den = sp.signal.welch(df[col], fs=2)\n",
    "    Pxx_den = np.sqrt(Pxx_den)\n",
    "\n",
    "    peaks = sp.signal.find_peaks(Pxx_den)[0]\n",
    "    prominences = sp.signal.peak_prominences(Pxx_den, peaks)[0]\n",
    "\n",
    "    idx_max = prominences.argmax()\n",
    "    loc_max = peaks[idx_max]\n",
    "\n",
    "    return [f[loc_max], Pxx_den[loc_max], prominences[idx_max]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking & Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wip; need to decide chunk size eventually\n",
    "## should we also make this chunking feature be our feature creation?\n",
    "\n",
    "def chunk_data(df, interval=60):\n",
    "\n",
    "    \"\"\"\n",
    "    takes in a filepath to the data you want to chunk and feature engineer\n",
    "    chunks our data into a specified time interval\n",
    "    each chunk is then turned into an observation to be fed into our classifier\n",
    "    \"\"\"\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    df['Time'] = df['Time'] - df['Time'].min()\n",
    "    \n",
    "    total_chunks = np.floor(df['Time'].max() / interval).astype(int)\n",
    "\n",
    "    for chunk in np.arange(total_chunks):\n",
    "      \n",
    "        start = chunk * interval\n",
    "        end = (chunk+1) * interval\n",
    "\n",
    "        temp_df = (df[(df['Time'] >= start) & (df['Time'] < end)])\n",
    "        \n",
    "        df_list.append(temp_df)\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(dfs, interval=60):\n",
    "\n",
    "  features = [\n",
    "    'dwl_peak_freq',\n",
    "    'dwl_peak_prom',\n",
    "    'dwl_max_psd',\n",
    "    'dwl_bytes_avg',\n",
    "    'dwl_bytes_std',\n",
    "    'dwl_peak_avg',\n",
    "    'dwl_peak_var',\n",
    "    'dwl_peak_std',\n",
    "    'upl_peak_freq',\n",
    "    'upl_peak_prom',\n",
    "    'upl_max_psd',\n",
    "    'upl_bytes_avg',\n",
    "    'upl_bytes_std',\n",
    "    'upl_peak_avg',\n",
    "    'upl_peak_var',\n",
    "    'upl_peak_std',\n",
    "      'IMAN_dwn_time_peak',#'IMAN_up_time_peak',\n",
    "      'IMAN_dwn_num_peak'#,'IMAN_up_num_peak'\n",
    "  ]  \n",
    "\n",
    "  vals = []\n",
    "  for df in dfs:\n",
    "      df_chunks = chunk_data(df, interval)\n",
    "\n",
    "      for chunk in df_chunks:\n",
    "\n",
    "        preproc = convert_ms_df(chunk, True)\n",
    "        upl_bytes = preproc[preproc['pkt_src'] == '1'].resample('500ms', on='Time').sum()\n",
    "        dwl_bytes = preproc[preproc['pkt_src'] == '2'].resample('500ms', on='Time').sum()\n",
    "\n",
    "        ## spectral features\n",
    "        dwl_spectral = spectral_features(dwl_bytes, 'pkt_size')\n",
    "        upl_spectral = spectral_features(upl_bytes, 'pkt_size')\n",
    "\n",
    "        ## aggregate features\n",
    "        dwl_agg = agg_feat(chunk, '2->1Bytes')\n",
    "        upl_agg = agg_feat(chunk, '1->2Bytes')\n",
    "\n",
    "        ## peak features\n",
    "        dwl_peak = peak_time_diff(chunk, '2->1Bytes')\n",
    "        upl_peak = peak_time_diff(chunk, '1->2Bytes')\n",
    "        \n",
    "        ## iman's time between peak \n",
    "        iman_dwn_time_peak = np.mean(peak_times(chunk,'2->1Bytes',1000000))\n",
    "        #iman_up_time_peak = np.mean(peak_times(chunk,'1->2Bytes',50000))\n",
    "        \n",
    "        ## iman's num peak\n",
    "        iman_dwn_num_peak = num_peaks(chunk,'2->1Bytes',1000000)\n",
    "        #iman_up_num_peak = num_peaks(chunk,'1->2Bytes',50000)\n",
    "\n",
    "\n",
    "        \n",
    "        feat_val = np.hstack((\n",
    "          dwl_spectral,\n",
    "          dwl_agg,\n",
    "          dwl_peak,\n",
    "          upl_spectral,\n",
    "          upl_agg,\n",
    "          upl_peak,\n",
    "            iman_dwn_time_peak,#iman_up_time_peak,\n",
    "            iman_dwn_num_peak,#iman_up_num_peak\n",
    "        ))\n",
    "\n",
    "        vals.append(feat_val)\n",
    "    \n",
    "  return pd.DataFrame(columns=features, data=vals).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 293 ms, total: 11 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "low_feat = create_features(low_dfs, 100)\n",
    "med_feat = create_features(med_dfs, 100)\n",
    "high_feat = create_features(high_dfs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# low_feat = create_features(stdoan_low, 100)\n",
    "# med_feat = create_features(stdoan_med, 100)\n",
    "# high_feat = create_features(stdoan_high, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_feat['resolution'] = np.zeros(len(low_feat))\n",
    "med_feat['resolution'] = np.zeros(len(med_feat)) + 1\n",
    "high_feat['resolution'] = np.zeros(len(high_feat)) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([low_feat, med_feat, high_feat]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training.drop(columns=['resolution']), training['resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=8,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 8, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwl_peak_freq</th>\n",
       "      <th>dwl_peak_prom</th>\n",
       "      <th>dwl_max_psd</th>\n",
       "      <th>dwl_bytes_avg</th>\n",
       "      <th>dwl_bytes_std</th>\n",
       "      <th>dwl_peak_avg</th>\n",
       "      <th>dwl_peak_var</th>\n",
       "      <th>dwl_peak_std</th>\n",
       "      <th>upl_peak_freq</th>\n",
       "      <th>upl_peak_prom</th>\n",
       "      <th>upl_max_psd</th>\n",
       "      <th>upl_bytes_avg</th>\n",
       "      <th>upl_bytes_std</th>\n",
       "      <th>upl_peak_avg</th>\n",
       "      <th>upl_peak_var</th>\n",
       "      <th>upl_peak_std</th>\n",
       "      <th>IMAN_dwn_time_peak</th>\n",
       "      <th>IMAN_dwn_num_peak</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>2.559624e+05</td>\n",
       "      <td>2.283896e+05</td>\n",
       "      <td>114425.905263</td>\n",
       "      <td>305025.605472</td>\n",
       "      <td>820.454545</td>\n",
       "      <td>5.367184e+05</td>\n",
       "      <td>732.610695</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>13224.990587</td>\n",
       "      <td>10583.824498</td>\n",
       "      <td>7366.642105</td>\n",
       "      <td>17675.769254</td>\n",
       "      <td>820.454545</td>\n",
       "      <td>6.460564e+05</td>\n",
       "      <td>803.776356</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>1.608469e+05</td>\n",
       "      <td>1.473483e+05</td>\n",
       "      <td>58461.855072</td>\n",
       "      <td>183186.907760</td>\n",
       "      <td>1479.200000</td>\n",
       "      <td>1.589888e+06</td>\n",
       "      <td>1260.907514</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>10074.840733</td>\n",
       "      <td>9316.483272</td>\n",
       "      <td>3780.942029</td>\n",
       "      <td>9327.334796</td>\n",
       "      <td>1479.200000</td>\n",
       "      <td>1.589888e+06</td>\n",
       "      <td>1260.907514</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>2.153807e+05</td>\n",
       "      <td>2.039448e+05</td>\n",
       "      <td>40925.519481</td>\n",
       "      <td>156778.675598</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>2.778365e+05</td>\n",
       "      <td>527.101983</td>\n",
       "      <td>0.304569</td>\n",
       "      <td>12063.980132</td>\n",
       "      <td>11423.459269</td>\n",
       "      <td>3293.870130</td>\n",
       "      <td>8072.574910</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>2.778365e+05</td>\n",
       "      <td>527.101983</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.429319</td>\n",
       "      <td>1.678943e+05</td>\n",
       "      <td>1.543345e+05</td>\n",
       "      <td>51165.656250</td>\n",
       "      <td>212334.491065</td>\n",
       "      <td>1633.333333</td>\n",
       "      <td>1.472686e+06</td>\n",
       "      <td>1213.542839</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>9448.058128</td>\n",
       "      <td>8840.608035</td>\n",
       "      <td>3652.531250</td>\n",
       "      <td>10500.679157</td>\n",
       "      <td>1633.333333</td>\n",
       "      <td>1.472686e+06</td>\n",
       "      <td>1213.542839</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.888234e+05</td>\n",
       "      <td>1.394501e+05</td>\n",
       "      <td>49224.350649</td>\n",
       "      <td>170981.928605</td>\n",
       "      <td>1729.800000</td>\n",
       "      <td>1.760775e+06</td>\n",
       "      <td>1326.941807</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12246.146287</td>\n",
       "      <td>10209.228504</td>\n",
       "      <td>3438.961039</td>\n",
       "      <td>8511.764942</td>\n",
       "      <td>1729.800000</td>\n",
       "      <td>1.760775e+06</td>\n",
       "      <td>1326.941807</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>1.097268e+06</td>\n",
       "      <td>1.043545e+06</td>\n",
       "      <td>253738.413043</td>\n",
       "      <td>580189.681359</td>\n",
       "      <td>902.500000</td>\n",
       "      <td>3.431702e+05</td>\n",
       "      <td>585.807349</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>53262.247600</td>\n",
       "      <td>52123.889925</td>\n",
       "      <td>13293.500000</td>\n",
       "      <td>27622.507815</td>\n",
       "      <td>902.500000</td>\n",
       "      <td>3.431702e+05</td>\n",
       "      <td>585.807349</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>9.765048e+05</td>\n",
       "      <td>8.906232e+05</td>\n",
       "      <td>217527.819444</td>\n",
       "      <td>516862.726467</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>1.714066e+06</td>\n",
       "      <td>1309.223625</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>46129.569359</td>\n",
       "      <td>41808.893237</td>\n",
       "      <td>11329.333333</td>\n",
       "      <td>24669.122888</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>1.714066e+06</td>\n",
       "      <td>1309.223625</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>5.251847e+05</td>\n",
       "      <td>4.571161e+05</td>\n",
       "      <td>229211.126437</td>\n",
       "      <td>575108.238130</td>\n",
       "      <td>921.600000</td>\n",
       "      <td>8.172820e+05</td>\n",
       "      <td>904.036526</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>25874.543373</td>\n",
       "      <td>24163.202914</td>\n",
       "      <td>11889.528736</td>\n",
       "      <td>27504.462558</td>\n",
       "      <td>921.600000</td>\n",
       "      <td>8.172820e+05</td>\n",
       "      <td>904.036526</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.438776</td>\n",
       "      <td>8.523427e+05</td>\n",
       "      <td>8.051908e+05</td>\n",
       "      <td>221431.108108</td>\n",
       "      <td>578239.976452</td>\n",
       "      <td>435.125000</td>\n",
       "      <td>1.715989e+05</td>\n",
       "      <td>414.244927</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>40051.038123</td>\n",
       "      <td>37570.814535</td>\n",
       "      <td>11485.864865</td>\n",
       "      <td>27438.619912</td>\n",
       "      <td>435.125000</td>\n",
       "      <td>1.715989e+05</td>\n",
       "      <td>414.244927</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>1.039235e+06</td>\n",
       "      <td>9.816971e+05</td>\n",
       "      <td>212427.789474</td>\n",
       "      <td>514930.758124</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>2.654244e+05</td>\n",
       "      <td>515.193599</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>48369.683326</td>\n",
       "      <td>45681.858790</td>\n",
       "      <td>11053.578947</td>\n",
       "      <td>24536.179618</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>2.654244e+05</td>\n",
       "      <td>515.193599</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dwl_peak_freq  dwl_peak_prom   dwl_max_psd  dwl_bytes_avg  dwl_bytes_std  \\\n",
       "0        0.072165   2.559624e+05  2.283896e+05  114425.905263  305025.605472   \n",
       "1        0.397959   1.608469e+05  1.473483e+05   58461.855072  183186.907760   \n",
       "2        0.851064   2.153807e+05  2.039448e+05   40925.519481  156778.675598   \n",
       "3        0.429319   1.678943e+05  1.543345e+05   51165.656250  212334.491065   \n",
       "4        0.666667   1.888234e+05  1.394501e+05   49224.350649  170981.928605   \n",
       "..            ...            ...           ...            ...            ...   \n",
       "94       0.100503   1.097268e+06  1.043545e+06  253738.413043  580189.681359   \n",
       "95       0.092308   9.765048e+05  8.906232e+05  217527.819444  516862.726467   \n",
       "96       0.183673   5.251847e+05  4.571161e+05  229211.126437  575108.238130   \n",
       "97       0.438776   8.523427e+05  8.051908e+05  221431.108108  578239.976452   \n",
       "98       0.092784   1.039235e+06  9.816971e+05  212427.789474  514930.758124   \n",
       "\n",
       "    dwl_peak_avg  dwl_peak_var  dwl_peak_std  upl_peak_freq  upl_peak_prom  \\\n",
       "0     820.454545  5.367184e+05    732.610695       0.070707   13224.990587   \n",
       "1    1479.200000  1.589888e+06   1260.907514       0.397959   10074.840733   \n",
       "2     900.000000  2.778365e+05    527.101983       0.304569   12063.980132   \n",
       "3    1633.333333  1.472686e+06   1213.542839       0.072539    9448.058128   \n",
       "4    1729.800000  1.760775e+06   1326.941807       0.500000   12246.146287   \n",
       "..           ...           ...           ...            ...            ...   \n",
       "94    902.500000  3.431702e+05    585.807349       0.100000   53262.247600   \n",
       "95    882.000000  1.714066e+06   1309.223625       0.092308   46129.569359   \n",
       "96    921.600000  8.172820e+05    904.036526       0.183673   25874.543373   \n",
       "97    435.125000  1.715989e+05    414.244927       0.122449   40051.038123   \n",
       "98    625.000000  2.654244e+05    515.193599       0.092784   48369.683326   \n",
       "\n",
       "     upl_max_psd  upl_bytes_avg  upl_bytes_std  upl_peak_avg  upl_peak_var  \\\n",
       "0   10583.824498    7366.642105   17675.769254    820.454545  6.460564e+05   \n",
       "1    9316.483272    3780.942029    9327.334796   1479.200000  1.589888e+06   \n",
       "2   11423.459269    3293.870130    8072.574910    900.000000  2.778365e+05   \n",
       "3    8840.608035    3652.531250   10500.679157   1633.333333  1.472686e+06   \n",
       "4   10209.228504    3438.961039    8511.764942   1729.800000  1.760775e+06   \n",
       "..           ...            ...            ...           ...           ...   \n",
       "94  52123.889925   13293.500000   27622.507815    902.500000  3.431702e+05   \n",
       "95  41808.893237   11329.333333   24669.122888    882.000000  1.714066e+06   \n",
       "96  24163.202914   11889.528736   27504.462558    921.600000  8.172820e+05   \n",
       "97  37570.814535   11485.864865   27438.619912    435.125000  1.715989e+05   \n",
       "98  45681.858790   11053.578947   24536.179618    625.000000  2.654244e+05   \n",
       "\n",
       "    upl_peak_std  IMAN_dwn_time_peak  IMAN_dwn_num_peak  resolution  \n",
       "0     803.776356           13.000000                2.0         0.0  \n",
       "1    1260.907514           -1.000000                0.0         0.0  \n",
       "2     527.101983           -1.000000                0.0         0.0  \n",
       "3    1213.542839           -1.000000                1.0         0.0  \n",
       "4    1326.941807           -1.000000                0.0         0.0  \n",
       "..           ...                 ...                ...         ...  \n",
       "94    585.807349           10.500000                9.0         2.0  \n",
       "95   1309.223625           10.400000                6.0         2.0  \n",
       "96    904.036526           13.333333                7.0         2.0  \n",
       "97    414.244927            8.428571                8.0         2.0  \n",
       "98    515.193599           10.714286                8.0         2.0  \n",
       "\n",
       "[99 rows x 19 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Species</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Species  0.0  1.0  2.0\n",
       "Actual Species                  \n",
       "0.0                  9    1    0\n",
       "1.0                  0    8    1\n",
       "2.0                  0    1    5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.crosstab(y_test, y_pred, rownames=['Actual Species'], colnames=['Predicted Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94736842, 0.84210526, 0.83333333])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwl_bytes_avg :  0.19400570497736236\n",
      "dwl_peak_prom :  0.11227263932552736\n",
      "dwl_max_psd :  0.1042636064227472\n",
      "dwl_bytes_std :  0.08968094200608726\n",
      "upl_bytes_std :  0.07848357699122407\n",
      "IMAN_dwn_num_peak :  0.06381409230154074\n",
      "upl_bytes_avg :  0.06055308573336525\n",
      "IMAN_dwn_time_peak :  0.05811615118452074\n",
      "upl_peak_std :  0.0565660596685456\n",
      "dwl_peak_std :  0.038137768880718986\n",
      "upl_peak_var :  0.03594913995472983\n",
      "upl_peak_avg :  0.027938730329112548\n",
      "upl_max_psd :  0.026433267677344052\n",
      "dwl_peak_var :  0.022523436077079007\n",
      "dwl_peak_freq :  0.011267126580791875\n",
      "upl_peak_freq :  0.010633962739230833\n",
      "upl_peak_prom :  0.009360709150072312\n",
      "dwl_peak_avg :  0.0\n"
     ]
    }
   ],
   "source": [
    "features = ['dwl_peak_freq','dwl_peak_prom','dwl_max_psd','dwl_bytes_avg','dwl_bytes_std','dwl_peak_avg',\n",
    "    'dwl_peak_var','dwl_peak_std','upl_peak_freq','upl_peak_prom','upl_max_psd','upl_bytes_avg','upl_bytes_std','upl_peak_avg','upl_peak_var','upl_peak_std',\n",
    "            'IMAN_dwn_time_peak',#'IMAN_up_time_peak'\n",
    "            'IMAN_dwn_num_peak']#,'IMAN_up_num_peak']\n",
    "importances = classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in indices:\n",
    "    print(features[i],': ',importances[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing that feature method functions correctly\n",
    "\n",
    "# l_start = 0 \n",
    "# l_end = 60\n",
    "\n",
    "# test_chunk = stdoan_low.copy()\n",
    "# test_chunk['Time'] = test_chunk['Time'] - test_chunk['Time'].min()\n",
    "# low_chunk = stdoan_low[(stdoan_low['Time'] >= 0) & (stdoan_low['Time'] < 60)]\n",
    "\n",
    "# low_chunk_ms = convert_ms_df(low_chunk, True)\n",
    "\n",
    "# upl_ms = low_chunk_ms[low_chunk_ms['pkt_src'] == '1']\n",
    "# dwl_ms = low_chunk_ms[low_chunk_ms['pkt_src'] == '2']\n",
    "\n",
    "# dwl_chunk_rs = dwl_ms.resample('500ms', on='Time').sum()\n",
    "\n",
    "# f_dwl, Pxx_dwl = sp.signal.welch(dwl_chunk_rs['pkt_size'], fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
